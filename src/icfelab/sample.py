"""Module for sampling functions from gaussian processes. This includes an executable script for plotting single
sampled functions. This code has partially been generated by a LLM."""
import argparse
import json
import lzma
from pathlib import Path
from typing import Any, Dict

import numpy as np
import torch
from numpy import ndarray
from scipy.stats import beta
from sklearn.gaussian_process import GaussianProcessRegressor
from tqdm import tqdm

from icfelab.utils import plot_test, create_covariance


def beta_sample_single_value(alpha: float = 5.0, beta_param: float = 5.0, scale: float = 1.0) -> float:
    """
    Samples a length_scale from a Beta distribution and rescales it.

    Parameters:
        alpha (float): Alpha parameter of the Beta distribution.
        beta_param (float): Beta parameter of the Beta distribution.
        scale (float): Maximum value for rescaling (default is 1.0 for [0, 1] range).

    Returns:
        float: A sampled length_scale value.
    """
    sampled_value = beta.rvs(alpha, beta_param)
    return sampled_value * scale


def sample_gp_rbf(x: np.ndarray, gaussian_process: GaussianProcessRegressor) -> ndarray:
    """Samples a function from a Gaussian Process with RBF kernel.
    Parameters:
        x(ndarray): The input values for which to sample the function.
        gaussian_process(GaussianProcessRegressor): The Gaussian Process instance.
    Returns:
        ndarray: sampled function values.
        """
    return gaussian_process.sample_y(x, n_samples=1).ravel()  # type: ignore


def generate_functions(args: argparse.Namespace) -> None:
    """Generate a number of functions and draw random samples of at least length 10 from all function points.
    Add gaussian noise to the sampled data with a random sampled std for each function.
    Args:
        number_functions: number of functions to generate.
        target_path: Path to the target file.
    """
    number_functions, target_path = args.number_functions, Path(args.target_file)
    grid_length = 128
    result_list = []
    for _ in tqdm(range(number_functions), desc="Generating functions", unit="functions"):
        rbf_scale = beta_sample_single_value(args.alpha, args.beta)
        co_var, rbf_kernel = create_covariance(rbf_scale, grid_length=grid_length)
        function = np.random.multivariate_normal(mean=np.zeros(co_var.shape[0]), cov=co_var, size=1).squeeze()
        data = sample_random_observation_grids(function, args.max, args.min)

        std = abs(np.random.normal(0, 0.1, 1).item())
        data["values"] = add_gaussian_noise(data["values"], 0, std)  # type: ignore

        result_list.append({"target": function.tolist(), "input": data, "rbf_scale": rbf_scale, "std": std})

    if args.plot:
        for i, result in enumerate(result_list):
            plot_test(torch.tensor(result["target"]), torch.tensor(result["input"]["indices"]),
                      torch.tensor(result["input"]["values"]), Path(f"data/generate/{i}"))
    save_compressed_json(result_list, target_path)


def sample_random_observation_grids(function: np.ndarray, max: int, min: int) -> Dict[str, list]:
    """Generate random grids to select a random number of points from this function."""
    function_size = len(function)
    indices = np.arange(function_size)
    number_of_points = np.random.randint(min, max + 1)
    random_grid = np.random.choice(indices, size=number_of_points, replace=False)
    random_grid.sort()
    return {"values": function[random_grid].tolist(), "indices": random_grid.tolist()}


def add_gaussian_noise(data: list, mean: float, std: float) -> ndarray:
    """
    Add gaussian noise to data.
    """
    data_ndarray = np.array(data)
    noise = np.random.normal(loc=mean, scale=std, size=data_ndarray.shape)
    return (data_ndarray + noise).tolist()


def save_compressed_json(serializable_object: Any, target_path: Path) -> None:
    """Compress and save json object."""
    json_str = json.dumps(serializable_object)
    json_bytes = json_str.encode('utf-8')

    target_path.parent.mkdir(parents=True, exist_ok=True)
    with lzma.open(target_path, 'wb') as file:
        file.write(json_bytes)


def get_args() -> argparse.Namespace:
    """
    Defines arguments.

    Returns:
        Namespace with parsed arguments.
    """
    parser = argparse.ArgumentParser(description="Sample random target interpolation functions.")
    parser.add_argument(
        "--target_file",
        "-f",
        type=str,
        default="functions.xz",
        help="File to save sampled functions to."
    )
    parser.add_argument(
        "--number-functions",
        "-n",
        type=int,
        default=100,
        help="Number of functions to generate."
    )
    parser.add_argument(
        "--plot",
        "-p",
        action="store_true",
        help="Plot sampled functions additionally to saving them. This is for debugging purposes, as it takes a lot "
             "of time for large amounts of data."
    )
    parser.add_argument(
        "--alpha",
        type=float,
        default=1,
        help="Beta distribution parameter for gaussian kernel scale."
    )
    parser.add_argument(
        "--beta",
        type=float,
        default=1,
        help="Beta distribution parameter for gaussian kernel scale."
    )
    parser.add_argument(
        "--max",
        type=int,
        default=50,
        help="Maximum number of samples in the observation grid."
    )
    parser.add_argument(
        "--min",
        type=int,
        default=5,
        help="Minimum number of samples in the observation grid"
    )
    return parser.parse_args()


if __name__ == "__main__":
    # todo: load grid length from config
    args = get_args()
    generate_functions(args)
